\section{Definitions}
\begin{align}
c_i & \text{ is the probability of doing $i$ damage} \\
c_0 & \text{ is the probability of doing zero damage} \\
c_+ &= 1 - c_0 \text{ is the probability of doing damage} \\
m & \text{ is the largest non-zero probability from $c_i$} \\
\end{align}

\section{Recursive Equation}
In one attack, the opponent can be brought to a given health $i$, from their initial health $h$ according to the transition probability, 
\begin{align}
	\pi_{h, i} &= \begin{cases}
		P(X=h - i) & \text{if } i > 0 \\
		P(X \ge h) & \text{if } i = 0
    \end{cases}
\end{align}
The probability they are killed in $L$ turns can be given by the sum of the probabilities the opponent was brought to $i$, then killed in $L - 1$ turns:
\begin{align}
	P_{h, L} &= \sum_{i=0}^\infty \pi_{h, i} P_{i, L-1}\\
	&= \cancel{\pi_{h, 0} P_{0, L-1}} + \pi_{h, h} P_{h, L-1} + \sum_{i=1}^{h-1} \pi_{h, i} P_{i, L-1} + \sum_{i=h+1}^\infty \pi_{h, i} P_{i, L-1}\\
	&= c_0P_{h, L-1} + \sum_{i=1}^{h-1} \pi_{h, i} P_{i, L-1} + \cancel{\sum_{i=h+1}^\infty \pi_{h, i} P_{i, L-1}}\\
	P_{h, L} &= c_0P_{h, L-1} + \sum_{i=\max(h-m, 1)}^{h-1} c_{h-i} P_{i, L-1}\\
\end{align}
where in the second line, the $i=0, h$ terms are explicitly considered, and the remaining sum is split in two. In the third line, $\pi_{h, i}$ would correspond to healing which we are taking to be zero. In the final line, we get the lower bound by considering that 
\begin{align}
	1\leq i \leq h-1 \implies& \pi_{h, i} = c_{h-i} \text{ if } 1\leq h - i \leq m \text{ otherwise } 0,\,\,\, \\
	\implies& 1\leq h - i \text{ and } h - i \leq m\\
	&\therefore  i\leq h - 1 \text{ and } h - m \leq i.
\end{align}
Since the first condition is already met, we have that $i \geq h - m$, but $i$ also cannot be below 1, hence $i\geq \max(h - m, 1)$. 



\section{Solution}
	The recursive equation to solve is:
	\begin{align}
		P_{h, L} &= c_0P_{h, L - 1} + \sum_{i\in I_h} c_{h-i} P_{i, L-1},\,\,\, L \ge 2, h \ge 1\\ % maybe 2
	\end{align}
	where $I_h$ is the set of integers satisfying $h - 1 \ge i \ge \max(h - m, 1)$. The boundary conditions are given by:
	\begin{align}
		P_{h, 1} &= \sum_{i=h}^m c_i \text{ (P of doing more than h damage)} \\
		 &= \theta(m - h) \sum_{i=h}^m c_i \\
		P_{1, L} &= c_+ c_0^{L-1} \text{ (P of missing $L-1$ times, then hitting any damage}\\
		P_{1, 1} &= c_+ \text{ (P of doing any damage)}
	\end{align}
	
	Using a generating function:
	\begin{align}
		g(x, y) &= \sum_{h=1}^\infty\sum_{L=1}^\infty P_{h, L} y^h x^L \\
		&= \sum_{h=1}^\infty\left(P_{h, 1} y^h x + \sum_{L=2}^\infty P_{h, L} y^h x^L \right)\\
		&= \sum_{h=1}^\infty P_{h, 1} y^h x + \sum_{h=1}^\infty\sum_{L=2}^\infty P_{h, L} y^h x^L\\
		&= xyP_{1, 1} + \sum_{h=2}^\infty P_{h, 1} y^h x + \sum_{L=2}^\infty\left( P_{1,L} yx^L + \sum_{h=2}^\infty P_{h, L} y^h x^L \right)\\
		&= xyP_{1, 1}  + x\sum_{h=2}^\infty P_{h, 1} y^h + \sum_{L=2}^\infty P_{1,L} yx^L + \sum_{L=2}^\infty\sum_{h=2}^\infty P_{h, L} y^h x \\
		&= xyP_{1, 1}  + x\sum_{h=2}^\infty P_{h, 1} y^h  + y\sum_{L=2}^\infty P_{1,L} x^L + \sum_{L=2}^\infty\sum_{h=2}^\infty P_{h, L} y^hx^L \\
	\end{align}
	These are the boundaries of a grid (corner $+$ top $+$ left) plus a sum over the interior. 

	\subsection{Corner} 
	Let's focus on each term at a time, starting with the corner:
	\begin{align}
		xyP_{1, 1} = xyc_+
	\end{align}
	\subsection{Top}
	For the top, lets first note that $\max(m - h + 1, 0)$ is non-zero when $m - h + 1 \ge 1 \implies m \ge h$. Then,
	\begin{align}
		x\sum_{h=2}^\infty P_{h, 1} y^h &= x \sum_{h=2}^\infty \theta(m - h)\sum_{i=h}^m c_i y^h\\
		&= x\sum_{h=2}^m \sum_{i=h}^m c_i y^h \\
	\end{align}
	\subsection{Left}
	Now the left:
	\begin{align}
		y\sum_{L=2}^\infty P_{1,L} x^L &= y\sum_{L=2}^\infty c_+ c_0^{L-1} x^L \\
		&= y\frac{c_+}{c_0}\sum_{L=2}^\infty (c_0x)^L \\
		&= y\frac{c_+}{c_0}\left[\sum_{L=0}^\infty (c_0x)^L - 1 - c_0x\right]\\
		&= y\frac{c_+}{c_0}\left[\frac{1}{1-c_0x} - 1 - c_0x\right]\\
		&= y\frac{c_+}{c_0}\frac{1}{1-c_0x}\left[1 - (1-c_0x) - (1-c_0x)c_0x\right]\\
		&= y\frac{c_+}{c_0}\frac{1}{1-c_0x}\left[c_0^2x^2\right]\\
		&= y\frac{c_+}{c_0}\frac{c_0^2x^2}{1-c_0x}\\
	\end{align}
	\subsection{Interior}
	Now the interior:
	\begin{align}
		\sum_{L=2}^\infty\sum_{h=2}^\infty P_{h, L} y^hx^L &= \sum_{L=2}^\infty\sum_{h=2}^\infty \left(c_0P_{h, L - 1} + \sum_{i\in I_h} c_{h-i}P_{i, L-1}\right) y^hx^L\\
		&= \sum_{L=2}^\infty\sum_{h=2}^\infty c_0P_{h, L - 1}y^hx^L + \sum_{L=2}^\infty\sum_{h=2}^\infty\sum_{i\in I_h} c_{h-i}P_{i, L-1}y^hx^L\\
		\mathcal{I}(x, y)&= G(x, y) + R(x, y).
	\end{align}
	Let us also tackle this individually, starting with the $G$ term:
	\begin{align}
		G(x, y) = \sum_{L=2}^\infty\sum_{h=2}^\infty c_0P_{h, L - 1}y^hx^L &= c_0\sum_{L=1}^\infty\sum_{h=2}^\infty P_{h, L}y^hx^{L+1}\\
		&= c_0x\sum_{L=1}^\infty\sum_{h=2}^\infty P_{h, L}y^hx^L\\
		&= c_0x\sum_{L=1}^\infty\left( \sum_{h=1}^\infty P_{h, L}y^hx^L -  P_{1, L}yx^L\right)\\
		&= c_0x\sum_{L=1}^\infty\sum_{h=1}^\infty P_{h, L}y^hx^L -  c_0xy\sum_{L=1}^\infty P_{1, L}x^L\\
		&= c_0xg(x, y) -  c_+ c_0xy\sum_{L=1}^\infty c_0^{L-1}x^L\\
		&= c_0xg(x, y) -  c_+ c_0x^2y\sum_{L=1}^\infty c_0^{L-1}x^{L-1}\\
		&= c_0xg(x, y) -  c_+ c_0 x^2y \sum_{L=0}^\infty c_0^{L}x^L\\
		&= c_0xg(x, y) -  \frac{c_+ c_0x^2y}{1-c_0x}\\
		&= c_0xg(x, y) -  y\frac{c_+}{c_0}\frac{c_0^2x^2}{1-c_0x}
	\end{align}
	
	% Followed by $R$. 
	% First let's note that $I$ is a non-empty set when $h-1>=\max(m-h, 1)$, empirically this is equivalent to:
	% $$h\ge \max\left(\left\lceil \frac{m + 1}{2} \right\rceil, 2\right)\equiv M \ge 2$$
	For $R$, we will first need a term that tells us whether $h$ is in the set $I$, i.e. does $h$ satisfy $h-1>=\max(m-h, 1)$? You will actually see that we need the more general $h-1>=\max(m-h+n, 1)$. We will call this condition $\delta_{m, h}^n$ which is $1$ if satisfied and $0$ otherwise. Empirically, this can be expressed as:
	\begin{align}
		\delta_{m, h}^n = \begin{cases}
			0 & \text{ if } h = 1 \\
			0 & \text{ if } n > m \\
			1 & \text{ otherwise } \\
		\end{cases}
	\end{align}
	Since $h >=2$,
	\begin{align}
		\delta_{m, h}^n = \delta_m^n = \begin{cases}
			1 & \text{ if } n \le m\\
			0 & \text{ otherwise } \\
		\end{cases}
	\end{align}
	Now solving $R(x, y)= \sum_{L=2}^\infty\sum_{h=2}^\infty\sum_{i\in I} c_{h-i}P_{i, L-1}y^hx^L$ gives:
	\begin{align}
		R(x, y) &= \sum_{L=2}^\infty\sum_{h=2}^\infty\sum_{i=\max(h-m, 1)}^{h-1} c_{h-i}P_{i, L-1}y^hx^L\\
		&= x \sum_{L=1}^\infty\sum_{h=2}^\infty\sum_{i=\max(h-m, 1)}^{h-1} c_{h-i}P_{i, L}y^hx^L\\
		&= xy \sum_{L=1}^\infty\sum_{h=1}^\infty\sum_{i=\max(h-m+1, 1)}^{h} c_{h-i}P_{i, L}y^hx^L\\
		&= xy \sum_{L=1}^\infty\sum_{h=1}^\infty\left(c_0P_{h, L}\delta_m^1 + \sum_{i=\max(h-m+1, 1)}^{h-1} c_{h-i}P_{i, L}\right)y^hx^L\\
		&= c_0xy \sum_{L=1}^\infty\sum_{h=1}^\infty P_{h, L}x^L\delta_m^1 + xy \sum_{L=1}^\infty\sum_{h=1}^\infty\sum_{i=\max(h-m+1, 1)}^{h-1} c_{h-i}P_{i, L}y^hx^L\\
	\end{align}
	Notice that the $h=1$ term in the second set of sums yields 0.
	\begin{align}
		&= c_0 xy g(x, y)\delta_h^1 + xy \sum_{L=1}^\infty\sum_{h=2}^\infty\sum_{i=\max(h-m+1, 1)}^{h-1} c_{h-i}P_{i, L}y^hx^L\\
		&= c_0xy g(x, y)\delta_h^1 + xy^2 \sum_{L=1}^\infty\sum_{h=1}^\infty\sum_{i=\max(h-m+2, 1)}^{h} c_{h-i}P_{i, L}y^hx^L\\
		&= c_0xy g(x, y)\delta_h^1 + xy^2 \sum_{L=1}^\infty\sum_{h=1}^\infty\left(\sum_{i=\max(h-m+2, 1)}^{h} c_{h-i}P_{i, L}\right)y^hx^L\\
		&= c_0xy g(x, y)\delta_h^1 + xy^2 \sum_{L=1}^\infty\sum_{h=1}^\infty\left(P_{i, L}\delta_m^2 + \sum_{i=\max(h-m+2, 1)}^{h} c_{h-i}P_{i, L}\right)y^hx^L\\
		&= c_0xy g(x, y)\delta_h^1 + xy^2 \sum_{L=1}^\infty\sum_{h=1}^\infty P_{i, L}\delta_m^2 + c_+xy^2 \sum_{L=1}^\infty\sum_{h=1}^\infty\sum_{i=\max(h-m+2, 1)}^{h} c_{h-i}P_{i, L}y^hx^L\\
		&= c_0xy g(x, y)\delta_h^1 + xy^2 g(x, y)\delta_m^2 + xy^2 \sum_{L=1}^\infty\sum_{h=1}^\infty\sum_{i=\max(h-m+2, 1)}^{h} c_{h-i} P_{i, L}y^hx^L\\
	\end{align}
	These series continues until the `engine' producing terms has no more. The number of terms in this series is given by the maximum $n$ that is non-zero:
	\begin{align}
		\arg \max_n \delta_m^n = m,
	\end{align}
	and so,
	\begin{align}
		R(x, y) &= c_+ x g(x, y)\sum_{i=1}^m y^i
	\end{align}
	% Followed by the recursive term (you'll see where it gets the name):
	% \begin{align}
	% 	c_+ \sum_{L=2}^\infty\sum_{h=2}^\infty\sum_{i\in I} P_{i, L-1}y^hx^L &= c_+ \sum_{L=1}^\infty\sum_{h=2}^\infty\sum_{i\in I_h} P_{i, L}y^hx^{L+1}\\
	% 	&= c_+ \sum_{h=2}^\infty\sum_{L=1}^\infty\sum_{i\in I_h} P_{i, L}y^hx^{L+1}\\
	% 	&= c_+ x\sum_{L=1}^\infty\sum_{h=2}^\infty\sum_{i\in I_h} P_{i, L}y^hx^L\\
	% 	&= c_+ x\sum_{L=1}^\infty x^L\left[\sum_{h=2}^\infty \sum_{i=\max(m-h, 1)}^{h-1} P_{i, L}y^h\right]\\
	% 	&= c_+ x\sum_{L=1}^\infty x^L\left[y\sum_{h=1}^\infty \sum_{i=\max(m-h-1, 1)}^{h} P_{i, L}y^h\right]\\
	% 	&= c_+ x\sum_{L=1}^\infty x^L\left[y\sum_{h=1}^\infty \left(P_{h, L}y^h + \sum_{i=\max(m-h-1, 1)}^{h-1} P_{i, L}y^h \right)\right]\\
	% 	&= c_+ x\sum_{L=1}^\infty x^L\left[y\sum_{h=1}^\infty P_{h, L}y^h + y\sum_{h=1}^\infty\sum_{i=\max(m-h-1, 1)}^{h-1} P_{i, L}y^h \right]\\
	% 	&= c_+ xy\sum_{L=1}^\infty \sum_{h=1}^\infty P_{h, L}y^hx^L + c_+ xy\sum_{L=1}^\infty x^L\sum_{h=1}^\infty\sum_{i=\max(m-h-1, 1)}^{h-1} P_{i, L}y^h \\
	% 	&= c_+ xyg(x, y) + c_+ xy\sum_{L=1}^\infty \sum_{h=1}^\infty\sum_{i=\max(m-h-1, 1)}^{h-1} P_{i, L}y^hx^L \\
	% 	&= c_+ xg(x, y) \left(y + y^2 + ...\right) \\
	% 	&= c_+ xg(x, y) \frac{1}{1-y} \\
	% \end{align}
	Now let's combine everything:
	\begin{align} 
		g(x, y) &= xyc_+ + x \sum_{h=2}^m \sum_{i=h}^{m}c_i y^h + \cancel{y\frac{c_+}{c_0}\frac{c_0^2x^2}{1-c_0x}} + c_0xg(x, y) - \cancel{y\frac{c_+}{c_0}\frac{c_0^2x^2}{1-c_0x}} +  x g(x, y)\sum_{i=1}^m c_{i} y^i\\
		&= x \sum_{h=1}^m\sum_{i=h}^{m}c_i y^h + c_0xg(x, y) + x g(x, y)\sum_{i=1}^m c_{i} y^i
	\end{align}
	Isolating for $g(x, y)$:
	\begin{align}
		g(x, y) - c_0xg(x, y) - x g(x, y)\sum_{i=1}^m c_{i} y^i &= x \sum_{h=1}^m\sum_{i=h}^{m}c_i y^h  \\
		g(x, y)\left[1 - c_0x - x \sum_{i=1}^m c_{i} y^i\right] &= x \sum_{h=1}^m\sum_{i=h}^{m}c_i y^h  \\
		g(x, y)\left[1 - x \sum_{i=0}^m c_{i} y^i\right] &= x \sum_{h=1}^m\sum_{i=h}^{m}c_i y^h  \\
		g(x, y) &= \frac{x \sum_{h=1}^m\sum_{i=h}^{m}c_i y^h}{1 - x \sum_{i=0}^m c_{i} y^i}
	\end{align}
	To simplify, let's define:
	\begin{align}
		T(y) &= \sum_{h=1}^m \sum_{i=h}^{m}c_i y^h\\
		B(y) &= \sum_{i=0}^m c_i y^i\\
	\end{align}
	Now $g(x, y)$ can be written as,
	\begin{align}
		g(x, y) &= T(y)\frac{x}{1- B(y)x}.
	\end{align}
	\newpage
	\subsection{Obtaining Power Series}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	To find the series representation of this, we will require the following identities:
	\begin{equation}\label{eq:binomial}
		(x + y)^n = \sum_{k=0}^n {n \choose k} x^{n-k}y^k
	\end{equation}
	\begin{equation}\label{eq:sub_binomial}
		(x - y)^n = \sum_{k=0}^n {n \choose k} (-1)^k x^{n-k}y^k
	\end{equation}
	\begin{equation}\label{eq:binomial_special}
		\frac{1}{(1-z)^\beta} = \sum_{k=0}^\infty {k + \beta -1 \choose k} z^k
	\end{equation}
	\begin{equation}\label{eq:geometric}
		\sum_{k=0}^n r^k = \frac{1 - r^{n+1}}{1 - r}
	\end{equation}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

	Let us start with:
	\begin{align}
		\frac{1}{1- B(y)x} &= \sum_{k=0}^\infty B^k(y)x^k \\
	\end{align}
	We need to workout $B^k(y)$:
	\begin{align}
		B^k(y) &= \left( \sum_{j=0}^m c_j y^j\right)^k \\
		&= \sum_{j=0}^{km} d_j^k y^j,
	\end{align}
	where $d_j^k$ is the $j$'th element of the $k$'th convolution of $c$, which doesn't have an analytic form. In practice the \texttt{numpy} function \texttt{numpy.polynomial.polynomial.polypow} can be used to compute this. Then,
	% https://en.wikipedia.org/wiki/Discrete_Fourier_transform#Polynomial_multiplication
	% https://caps.gsfc.nasa.gov/simpson/pubs/series.pdf also
	\begin{align}
		\frac{1}{1-B(y)x} &= \sum_{k=0}^\infty \left[ \sum_{j=0}^{km} d_j^k y^j \right] x^k \\
		\implies\frac{x}{1-B(y)x} &= \sum_{k=0}^\infty \left[ \sum_{j=0}^{km} d_j^k y^j \right] x^{k+1} \\
		&= \sum_{k=1}^\infty \sum_{j=0}^{(k-1)m} d_j^{k-1} y^j x^k
	\end{align}

	Multiplying by $T(y)$ gives back our generating function:
	\begin{align}
		g(x, y) = \frac{T(y)x}{1-B(y)x} &= T(y)\sum_{k=1}^\infty \sum_{j=0}^{(k-1)m} d_j^{k-1} y^j x^k\\
		&= \sum_{h=1}^m \sum_{i=h}^{m}c_i y^h \cdot \sum_{k=1}^\infty \sum_{j=0}^{(k-1)m} d_j^{k-1} y^j x^k\\
		&= \sum_{h=1}^m  \sum_{k=1}^\infty \sum_{j=0}^{(k-1)m} \sum_{i=h}^{m} c_i d_j^{k-1} y^{j+h} x^k\\
		&= \sum_{h=1}^m  \sum_{k=1}^\infty \sum_{j=0}^{(k-1)m} a_{h, j}^k y^{j+h} x^k,
	\end{align}
	where $a_{h, j}^k \equiv \sum_{i=h}^{m} c_i d_j^{k-1}$. We make use of the identity (visual proof omitted)
	\begin{align}
		\sum_{i=1}^N \sum_{j=0}^M a_{i, j}y^{i+j} = \sum_{p=1}^{N+M}\left[ \sum_{j=\max(1, p-M)}^{\min(p, N)} a_{j, p-j}\right]y^p
	\end{align}
	with $h=i, j=j, N=m, M=(k-1)m$ to obtain:
	\begin{align}
		g(x, y) &= \sum_{k=1}^\infty \sum_{p=1}^{km} \left[\sum_{j=\max(1, p+(1-k)m)}^{\min(p, m)} a_{j, p-j}^k \right]y^px^k\\
		 &= \sum_{L=1}^\infty \sum_{h=1}^{Lm} \left[\sum_{j=\max(1, h+(1-L)m)}^{\min(h, m)} a_{j, h-j}^L \right]y^h x^L\\
		 &= \sum_{L=1}^\infty \sum_{h=1}^{\infty} \left[\theta(Lm-h)\sum_{j=\max(1, h+(1-L)m)}^{\min(h, m)} a_{j, h-j}^L \right]y^h x^L
	\end{align}
	where $\theta(x)$ is the Heaviside function. Extracting out $P_{h, L}$, we get,
	\begin{align}
		P_{h, L} &= \theta(Lm-h)\sum_{j=\max(1, h+m-mL)}^{\min(h, m)} a_{j, h-j}^L \\
		P_{h, L} &= \theta(Lm-h)\sum_{j=\max(1, h+m-mL)}^{\min(h, m)} \sum_{i=h}^m c_i d_{h-j}^{L-1}
	\end{align}
	And so we end with:
	\begin{equation}
		\boxed{\therefore P_{h, L} = \theta(Lm-h)\sum_{j=\max(1, h+m-mL)}^{\min(h, m)} \sum_{i=h}^m c_i d_{h-j}^{L-1} }
	\end{equation}
	

	\section{Summing over $L$}
		Often, the following quantity needs to be evaluated for further applications, like the probability of winning a fight:
		\begin{equation}
			\sum_{L=b}^\infty P_{h, L} = P_{h, 1}\sum_{L=b}^\infty c_0^{L-1}  + \sum_{i=1}^{\min(h, m)} \sum_{L=b}^\infty H_{h, i}^L,
		\end{equation}
		

		Tackling the first term, we get: % https://en.wikipedia.org/wiki/Geometric_progression, related formulas
		\begin{align}
			\sum_{L=b}^\infty c_0^{L-1} &= \sum_{L=b-1}^\infty c_0^{L} \\
			&= \frac{c_0^{b-1}}{1 - c_0} \\
		\end{align}

		% \newpage
		For the second term, we need:
		\begin{align}
			\sum_{i=a}^\infty {i \choose k} x^i &= \sum_{i=1}^\infty {i \choose k} x^i - \sum_{i=1}^{a-1} {i \choose k} x^i,\,\,\,1\leq k \leq a\\
			&= \frac{x^k}{(1-x)^{k+1}} - \sum_{i=1}^{a-1} {i \choose k} x^i\\
		\end{align}

		Focusing on the second term,
		\begin{align}
			\sum_{L=b}^\infty H_{h, i}^L &= C_i \sum_{L=b}^\infty  c_0^{L-1} \sum_{p=1}^{\min_{h-i}^{L-1}} {L-1 \choose p}  G(h, i, p)\\
			&= C_i \sum_{L=b}^\infty  \left[ \sum_{p=1}^{\min_{h-i}^{L-1}} c_0^{L-1}{L-1 \choose p}  G(h, i, p) \right]\\
			&= C_i \sum_{L=b}^{h-i} \sum_{p=1}^{L-1} c_0^{L-1}{L-1 \choose p}  G(h, i, p) + C_i \sum_{L=\max^b_{h-i+1}}^{\infty} \sum_{p=1}^{h-i} c_0^{L-1}{L-1 \choose p}  G(h, i, p)\\
			&= C_i \sum_{L=b}^{h-i} \sum_{p=1}^{L-1} c_0^{L-1}{L-1 \choose p}  G(h, i, p) + C_i  \sum_{p=1}^{h-i} \left[\sum_{L=\max^b_{h-i+1}}^{\infty} c_0^{L-1}{L-1 \choose p}  \right]G(h, i, p)\\
			&= C_i \sum_{L=b}^{h-i} \sum_{p=1}^{L-1} c_0^{L-1}{L-1 \choose p}  G(h, i, p) + C_i  \sum_{p=1}^{h-i} \left[\sum_{L=\max^{b-1}_{h-i}}^{\infty} c_0^{L}{L \choose p}  \right]G(h, i, p)\\
			&= C_i \sum_{L=b}^{h-i} \sum_{p=1}^{L-1} c_0^{L-1}{L-1 \choose p}  G(h, i, p) + C_i  \sum_{p=1}^{h-i} \left[\sum_{L=0}^{\infty} c_0^{L}{L \choose p} - \sum_{L=0}^{\max^{b - 1}_{h - i} - 1} c_0^{L}{L \choose p}  \right]G(h, i, p)\\
			&= C_i \sum_{L=b}^{h-i} \sum_{p=1}^{L-1} c_0^{L-1}{L-1 \choose p}  G(h, i, p) + C_i  \sum_{p=1}^{h-i} \left[\frac{c_0^p}{(1-c_0)^{p+1}} - \sum_{L=0}^{\max^{b - 1}_{h - i} - 1} c_0^{L}{L \choose p}  \right]G(h, i, p)\\
			&= C_i \sum_{L=b}^{h-i} \sum_{p=1}^{L-1} c_0^{L-1}{L-1 \choose p}  G(h, i, p) + C_i  \sum_{p=1}^{h-i} \left[\frac{c_0^p}{(1-c_0)^{p+1}} - \sum_{L=1}^{\max^{b - 1}_{h - i} - 1} {L \choose p} c_0^L \right]G(h, i, p)  % Since j=0 term is zero.
		\end{align}
		Having removed any infinities, this equation is now computationally feasible. It can be used in further calculations like the probability a player kills their opponent before they are killed.









	% If we define,
	% \begin{align}
	% 	A_{j, k} \equiv \sum_{i=0}^{\min(\lfloor j / m \rfloor, k)} a_{i, j-mi}^k,
	% \end{align}
	% then,
	% \begin{equation}
	% 	\sum_{j=0}^\infty \sum_{i=0}^k a_{i, j}^k y^{mi +j} = \sum_{j=0}^\infty A_{j, k}y^j.
	% \end{equation}
	% and so,
	% \begin{align}
	% \sum_{k=1}^\infty \left[ \sum_{j=0}^\infty \sum_{i=0}^k a_{i, j}^k y^{mi +j}\right]y^k x^k &= \sum_{k=1}^\infty \left[\sum_{j=0}^\infty A_{j, k}y^j \right] y^kx^k\\
	% &= \sum_{k=1}^\infty \sum_{j=0}^\infty A_{j, k} y^{k+j}x^k\\
	% &= \sum_{k=1}^\infty \sum_{n=k}^\infty A_{n-k, k} y^{n}x^k\\
	% \end{align}
	% Therefore,
	% \begin{align}
	% \frac{1}{1-B(y)x} &= 1 + \sum_{k=1}^\infty \sum_{n=k}^\infty A_{n-k, k} y^{n}x^k\\
	% \implies\frac{x}{1-B(y)x} &= x + \sum_{k=1}^\infty \sum_{n=k}^\infty A_{n-k, k} y^{n}x^{k+1}\\
	% &= x + \sum_{k=2}^\infty \sum_{n=k-1}^\infty A_{n-k+1, k-1} y^{n}x^k\\
	% \end{align}
	% Now,
	% \begin{align}
	% T(y)\frac{x}{1-B(y)x} &= T(y)x + T(y)\sum_{k=2}^\infty \sum_{n=k-1}^\infty A_{n-k+1, k-1} y^{n}x^k\\
	% &= T(y)x + c_+ \sum_{h=1}^m (m - h + 1)y^h\sum_{k=2}^\infty \sum_{n=k-1}^\infty A_{n-k+1, k-1} y^{n}x^k\\
	% &= T(y)x + c_+ \sum_{k=2}^\infty \sum_{n=k-1}^\infty \left[\sum_{h=1}^m (m - h + 1)A_{n-k+1, k-1} y^{n+h} \right]x^k\\
	% \end{align}
	% Define,
	% \begin{align}
	% 	\gamma_{n, k}^h \equiv (m - h + 1)A_{n-k+1, k-1}
	% \end{align}
	% Now,
	% \begin{align}
	% 	T(y)\frac{x}{1-B(y)x} &= T(y)x + c_+ \sum_{k=2}^\infty \left[\sum_{n=k-1}^\infty \sum_{h=1}^m \gamma_{n, k}^h y^{h+n} \right]x^k\\
	% \end{align}
	% To handle this, we make use of the identity [visual proof is also omitted]:
	% \begin{align}
	% 	\sum_{n=b}^\infty \sum_{h=1}^m a_{n, h} y^{n+h} = \sum_{n=b+1}^\infty\left( \sum_{h=1}^{\min(n-b, m)}a_{n-h, h} \right) y^n
	% \end{align}
	% So now,
	% \begin{align}
	% 	g(x, y) &= T(y)x + c_+ \sum_{k=2}^\infty \left[\sum_{n=k}^\infty\left( \sum_{h=1}^{\min(n-k+1, m)}\gamma_{n-h, k}^h \right) y^n \right]x^k\\
	% 	&= T(y)x + \sum_{k=2}^\infty \sum_{n=k}^\infty\left( \sum_{h=1}^{\min(n-k+1, m)}c_+\gamma_{n-h, k}^h \right) y^n x^k\\
	% \end{align}
	% With a change of variables we get,
	% \begin{align}
	% 	\sum_{L=1}^\infty \sum_{h=1}^\infty P_{h, L} y^h x^L &= T(y)x + \sum_{L=2}^\infty \sum_{h=L}^\infty\left( \sum_{i=1}^{\min(h-L+1, m)}c_+\gamma_{h-i, L}^i \right) y^h x^L\\
	% 	\sum_{h=1}^\infty P_{h, 1} y^h x + \sum_{L=2}^\infty \sum_{h=1}^\infty P_{h, L} y^h x^L &= T(y)x + \sum_{L=2}^\infty \sum_{h=L}^\infty\left( \sum_{i=1}^{\min(h-L+1, m)}c_+\gamma_{h-i, L}^i \right) y^h x^L\\
	% 	% \implies P_{h, L} &= c_+ \sum_{j=1}^{\min(h - L + 1, m)} \gamma_{h-j, L}^j\\
	% \end{align}
	% Since the $x$ terms are trivially a boundary condition, let's focus on the double sums:
	% \begin{align}
	% 	\sum_{L=2}^\infty \sum_{h=1}^\infty P_{h, L} y^h x^L &= \sum_{L=2}^\infty \sum_{h=L}^\infty D_{h, L} y^h x^L\\
	% 	% \implies P_{h, L} &= c_+ \sum_{j=1}^{\min(h - L + 1, m)} \gamma_{h-j, L}^j\\
	% \end{align}
	\newpage
	\section{Summary}
		First, given a player's max hit of $m$ and an opponent's initial health of $h$, we define:
		\begin{align}
			c_+ &= \frac{a}{m+1} \\
			c_* &= mc_+ \\
			c_0 &= 1 - c_* \\
			C_i &= c_+ (m - i + 1)
		\end{align}
		where $c_0$ is the probability of doing zero damage, and $c_+$ is the probability of doing any positive amount of damage.
		Then, the probability of killing in $L$ turns is given by the recursive equation:
		\begin{align}
			P_{h, L} &= c_0P_{h, L - 1} + c_+ \sum_{i=\max{h - m, 1}}^{h-1} P_{i, L-1},\,\,\, L \ge 2, h \ge 1
		\end{align}
		The boundary conditions are given by:
		\begin{align}
			P_{h, 1} &= c_+ \max(m - h + 1, 0)\\
			P_{1, L} &= c_* c_0^{L-1}\\
			P_{1, 1} &= c_*
		\end{align}
		This has the following solution:
		\begin{equation}
			P_{h, L} = P_{h, 1}c_0^{L-1}  + \sum_{i=1}^{\min(h, m)} H_{h, i}^L,
		\end{equation}
		where
		\begin{align}
			H_{h, i}^L &\equiv c_+c_0^{L-1} (m - i + 1)\sum_{p=1}^{\min_{h-i}^{L-1}} {L-1 \choose p}  G(h, i, p) \\
			G(h, i, p) &\equiv \left(\frac{c_+}{c_0}\right)^p  \sum_{l=0}^{\min_{\lfloor (h-i-p) / m \rfloor}^{p}} (-1)^l  {p \choose l} {h-i-ml-1\choose h-i-ml-p}.
		\end{align}
		The probability of winning a fight with an opponent, and drawing is given by:
		\begin{align}
			P_\text{win} &= \sum_{L=1}^\infty \sum_{l=L+1}^\infty P_{h_\text{player}, l}^{m_\text{opponent}} P_{h_\text{opponent}, L}^{m_\text{player}}\\
			P_\text{draw} &= \sum_{L=1}^\infty P_{h_\text{player}, L}^{m_\text{opponent}} P_{h_\text{opponent}, L}^{m_\text{player}},
		\end{align}
		where $P_\text{win} + P_\text{lose} + P_\text{draw} = 1$ and swapping opponent values for player values turns $P_\text{win}$ into $P_\text{lose}$. The sum $\sum_{L=a}^\infty P_{h, L}$ can also be expressed in terms of a finite sum.

	\section{Comments}
		It would be useful to compute the time complexity required for evaluation. There is an infinite sum in both $P_\text{win}$ and $P_\text{lose}$ that must simply be truncated during evaluation. It would be nice to either find analytic solutions or determine appropriate cutoffs.
	
